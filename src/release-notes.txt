GBT Mapping Pipeline Version 1.0

These notes accompany the release of the GBT Mapping Pipeline on October 24,
2012.  The previous version of the pipeline was 0.4.  The most significant 
changes since the last release are to the calibration equations, the user 
interface and memory efficiency.  These are described below.

1)  Calibration equations  

We improved the calibration steps used in the pipeline.

The previous release defined

                        (Cal_on(v) + Cal_off(v))
    Tsys(v) = Tcal(v) * ------------------------
                        2*(Cal_on(v)-Cal_off(v))

        where  Tsys = Tsys(v) averaged over the center 80% of
            the frequency range of the observation
            and v is frequency
            
                      beam_scaling_factor * e^tau
    Ta*(v) = Ta(v) * -----------------------------
                             eta_l * Gain(z)
                          
        where Gain(z) = A_0 + A_1*z + A_2*z^2 + A_3*z^3,
           tau is the elevation-adjusted opacity,
           v is frequency and eta_l is the spillover factor

    Default units = Ta*
    
With this release, we assign Tsys as follows.  This definition is compatible 
with that used in GBTIDL.

                      Cal_off
    Tsys = Tcal * ---------------- + (Tcal / 2)
                  Cal_on - Cal_off

        where Cal_off and Cal_on are averaged over the center 80% of
            the frequency range of the observation
    
                      beam_scaling_factor * e^tau
    Ta*(v) = Ta(v) * -----------------------------
                                eta_l

In addition to these changes, we have modified the default units to be Tmb.

2) User interface

The command-line options have been revised for ease of use and flexibility.
On the gbtpipeline-announce mailing list we asked gbtpipeline users about their
experience with several exisiting parameters.  As a result, the following
options have been deprecated:

  --sdfits-dir or -d
  --map-scans-for-scale
  --fs-as-ps
  
In addition:

  --max-processors has been deprecated because it is no longer necessary
    to have a workaround for excessive memory consumption (see Memory
    efficiency below).
    
  --allmaps is no longer required for map discovery.  The pipeline will attempt
    to find maps in a dataset when the -m or --map-scans parameter is not set.

Other parameters have been combined, or renamed:

  --refscan1 and --refscan2 were replaced with --refscan.  --refscan
    can take a single scan number or a pair of scan numbers separated by a
    comma.  For example, '--refscan 13' or '--refscan 13,26'

  --gain-factors-left and --gain-factors-right were replaced with
    --beam-scaling.  --beam-scaling accepts a comma-separated list of beam
    scaling factors for each feed and polarization in the order
    0L,0R,1L,1R,etc.  For example, a 2 feed, 2 polarization data set would
    expect a list of 4 comma-separated values.
    
  --idlToSdfits-rms-flag was renamed --rms-flag
  
  --idlToSdfits-baseline-subtract was renamed --median-baseline-subtract
  
  --display-idlToSdfits was renamed --display-idlToSdfits-plots
    
There are also some new parameters:

  --keep-temporary-files does exactly what it says.  With this pipeline
    release, the default behavior is to have temporary files deleted at the 
    end of a pipeline run.  When this option is set, those files will remain.

  -w or --window allows the user to select a subset of spectral windows used
    in the observation for calibration and/or imaging.  The default behavior
    is to calibrate and image all spectral windows in the data set.
    
Finally, the .sdf files which are used as input into the doImage scripts are
no longer produced when --imaging-off is set at the command line.  Furthermore,
even when imaging is enabled, these files are removed by default.  If you have
your own modified imaging scripts and you want to use .sdf files as input, run
the pipeline with --keep-temporary-files and allow the default imaging steps
to occur.  At this point, you can run your doImage scripts as before, using the
.sdf files as input.

3) Memory efficiency

The new pipeline will calibrate data faster and with far less memory than in
previous releases.  Tests show up to a 10x speedup in calibration and memory
usage at no more than a couple gigabytes.  Large maps with long scans should
be processed just as efficiently as small maps.

Specifically, the previous releases had the limitation of needing to read an
entire scan into memory to perform the calibration step.  This usually was
not an issue when running on a machine like 'arcturus' with a large amount
of memory.  However, if a scan was particularly long and had a large number of
integrations, this could become problematic.  The workaround was to limit the
number of beams processed by the pipeline at the same time.  This was done
either by setting the --max-processors parameter or by running the pipeline on
a subset of the data using one of the data selection options like --feed or
--pol.  In the new release, the --max-processors parameter is no longer
necessary, and has been deprecated.
